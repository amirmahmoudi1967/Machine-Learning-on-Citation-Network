{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Windows\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Windows\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import numpy as np\n",
    "import networkx as nx #We used networkx since it is the library we used during the practice session\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/node_information.csv\", \"r\") as f:\n",
    "    file = csv.reader(f)\n",
    "    node_info = list(file)\n",
    "\n",
    "IDs = [int(element[0]) for element in node_info]\n",
    "\n",
    "with open(\"./data/training_set.txt\", \"r\") as f:\n",
    "    file =csv.reader(f, delimiter='\\t')\n",
    "    set_file=list(file)\n",
    "set= np.array([values[0].split(\" \") for values in set_file]).astype(int)\n",
    "\n",
    "\n",
    "#Define the directed graph and add the IDs\n",
    "directed_graph=nx.DiGraph()\n",
    "directed_graph.add_nodes_from(IDs)\n",
    "for ID_source_train,ID_sink_train,link_train in set:\n",
    "    if link_train==1:#the link are added if this statement is true\n",
    "        directed_graph.add_edge(ID_source_train,ID_sink_train)\n",
    "\n",
    "graph = nx.Graph(directed_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "Year = [int(element[1]) for element in node_info]\n",
    "Title = [element[2] for element in node_info]\n",
    "Authors=[element[3] for element in node_info]\n",
    "Journal_name=[element[4] for element in node_info]\n",
    "Corpus=[element[5] for element in node_info]\n",
    "\n",
    "page_rank = nx.pagerank_scipy(graph)\n",
    "hub_score, authority_score = nx.hits(graph)\n",
    "\n",
    "#TF-IDF cosine similarity\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(Corpus)\n",
    "\n",
    "#One hot encoding on node information for the cooccurence computation\n",
    "one_hot_encoder=CountVectorizer()\n",
    "Authors_encoded=one_hot_encoder.fit_transform(Authors)\n",
    "Titles_encoded=one_hot_encoder.fit_transform(Title)\n",
    "\n",
    "one_hot_corpus_encoding=CountVectorizer(stop_words=\"english\")\n",
    "corpus_encoded = one_hot_corpus_encoding.fit_transform(Corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(article_1,article_2):#To generate the features between 2 papers\n",
    "    article_1_id,article_2_id=IDs.index(article_1),IDs.index(article_2)\n",
    "\n",
    "    #tfidf cosine similarity\n",
    "    tf_1 ,tf_2= tfidf_matrix[1], tfidf_matrix[2]\n",
    "    tfidf_sim = cosine_similarity(tf_1, tf_2)[0][0]\n",
    "\n",
    "    ## Features from contextual information of the nodes\n",
    "    co_occurence_corpus=(corpus_encoded[article_1_id]@corpus_encoded[article_2_id].T).toarray()[0][0]\n",
    "    same_authors=(Authors_encoded[article_1_id]@Authors_encoded[article_2_id].T).toarray()[0][0]\n",
    "    co_occurence_title=(Titles_encoded[article_1_id]@Titles_encoded[article_2_id].T).toarray()[0][0]\n",
    "\n",
    "    same_journal = int(Journal_name[article_1_id] == Journal_name[article_2_id])\n",
    "    years_diff=Year[article_1_id]-Year[article_2_id]\n",
    "\n",
    "    #Feature from the directed graph\n",
    "\n",
    "    triad_features = [0.0]*8\n",
    "    for w in sorted(nx.common_neighbors(graph, article_1, article_2)):\n",
    "        if graph.has_edge(article_1, w) and graph.has_edge(w, article_2):\n",
    "            triad_features[0]+=1\n",
    "        if graph.has_edge(article_1, w) and graph.has_edge(article_2, w):\n",
    "            triad_features[1]+=1\n",
    "        if graph.has_edge(w, article_1) and graph.has_edge(w, article_2):\n",
    "            triad_features[2] += 1\n",
    "        if graph.has_edge(w, article_1) and graph.has_edge(article_2, w):\n",
    "            triad_features[3] += 1\n",
    "    for i in range(4, 8):\n",
    "        if triad_features[i-4]!=0:\n",
    "            triad_features[i] = triad_features[i-4]/common_neig\n",
    "\n",
    "    #Feature from the graph\n",
    "    adamic_adar=nx.adamic_adar_index(graph, [(article_1, article_2)])\n",
    "    for _,_,p in adamic_adar:\n",
    "        adamic_adar_coef= p\n",
    "    jaccard = nx.jaccard_coefficient(graph, [(article_1, article_2)])\n",
    "    for _,_,p in jaccard:\n",
    "        jaccard_coef= p\n",
    "    pref_attachement = nx.preferential_attachment(graph, [(article_1, article_2)])\n",
    "    for _,_,p in pref_attachement:\n",
    "        pref_attachement_coef= p\n",
    "    common_neig=len(sorted(nx.common_neighbors(graph, article_1, article_2)))\n",
    "\n",
    "\n",
    "    node_info_features = [co_occurence_corpus, same_authors, co_occurence_title, years_diff, same_journal, tfidf_sim]\n",
    "    degree_features = [directed_graph.in_degree(article_1), directed_graph.out_degree(article_1), directed_graph.in_degree(article_2), directed_graph.out_degree(article_2)]\n",
    "    heuristic_graph_features = [jaccard_coef, adamic_adar_coef, pref_attachement_coef, common_neig,page_rank[article_2],hub_score[article_1],authority_score[article_2]]\n",
    "\n",
    "    #We are returning 25 features\n",
    "    return node_info_features + heuristic_graph_features + degree_features + triad_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    X_train= np.load(\"./saved_data/X_train.npy\")\n",
    "    y_train=np.load(\"./saved_data/y_train.npy\")\n",
    "except:\n",
    "    y_train=[]\n",
    "    X_train= []\n",
    "    step=0\n",
    "    for source,sink,link in set:\n",
    "        step+=1\n",
    "        if step%1000==0:\n",
    "            print(\"Finished \",step,\"steps over \",len(set),end='\\r')\n",
    "        X_train.append(get_features(source,sink))\n",
    "        y_train.append(link)\n",
    "    X_train=np.array(X_train)\n",
    "    X_train = preprocessing.scale(X_train)\n",
    "    y_train=np.array(y_train)\n",
    "    np.save(\"./saved_data/X_train.npy\", X_train)\n",
    "    np.save(\"./saved_data/y_train.npy\", y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/testing_set.txt\", \"r\") as f:\n",
    "    file =csv.reader(f, delimiter='\\t')\n",
    "    set_file=list(file)\n",
    "set_test= np.array([values[0].split(\" \") for values in set_file]).astype(int)\n",
    "try:\n",
    "    X_test=np.load(\"./saved_data/X_test.npy\")\n",
    "except:\n",
    "    X_test=[]\n",
    "    y_test=[]\n",
    "    print(\"Features construction for Testing...\")\n",
    "    step=0\n",
    "    for source,sink in set_test:\n",
    "        step+=1\n",
    "        if step%1000==0:\n",
    "            print(\"Finished \",step,\"steps over \",len(set_test),end='\\r')\n",
    "        X_test.append(get_features(source,sink))\n",
    "    X_test=np.array(X_test)\n",
    "    X_test = preprocessing.scale(X_test)\n",
    "    np.save(\"./saved_data/X_test.npy\", X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction(model,model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = list(model.predict(X_test))\n",
    "    pred= zip(range(len(set_test)), y_pred)\n",
    "    filename=\"./submission/submit_\"+model_name+\".csv\"\n",
    "    with open(filename,\"w\",newline=\"\") as prediction:\n",
    "        fieldnames = ['id', 'category']\n",
    "        csv_out = csv.writer(prediction)\n",
    "        csv_out.writerow(fieldnames)\n",
    "        for row in pred:\n",
    "            csv_out.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "#run_prediction(svm.LinearSVC(),\"LinearSVC\") #Score: 0.96634 on kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#run_prediction(RandomForestClassifier(n_estimators=150),\"Random_Forest\") #Score: 0.97114 on kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#run_prediction(GradientBoostingClassifier(n_estimators=150, learning_rate=1e-2, random_state=0),\"GBoost\")#Score: 0.96988 on kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Light GBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "#run_prediction(lgb.LGBMClassifier(n_estimators=150),\"LGBM\") #Score: 0.96969 on kaggle\n",
    "#run_prediction(lgb.LGBMClassifier(n_estimators=150,learning_rate=1e-5,max_depth=9,min_child_weight=2,reg_alpha=3,min_child_samples=20)) \n",
    "#Score: 0.70594 on kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "#run_prediction(XGBClassifier(n_estimators=150),\"XGB\")#Score: 0.96006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning\n",
    "\n",
    "We decided to keep working on Light GBM regarding how well it performed on the kaggle submition also teh boosting type can be specified first we will try the classical gradient boosting decision tree and after the dropouts meet Multiple Additive Regression (DART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune(model,trainx,trainy,valx,valy):\n",
    "    model.fit(trainx, trainy)\n",
    "    y_pred = list(model.predict(valx))\n",
    "    return accuracy_score(valy,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainx, valx, trainy, valy) = train_test_split(X_train, y_train, test_size=0.3, random_state=26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_leaves=[30,40,50,60]\n",
    "min_child_samples=[20,30,40,50,60]\n",
    "reg_alpha=[i for i in range(5)]\n",
    "fine_tuning_lgbm=[]\n",
    "for nl in num_leaves:\n",
    "    for mcs in min_child_samples:\n",
    "        for ra in reg_alpha:\n",
    "            acc=fine_tune(lgb.LGBMClassifier(n_estimators=100,num_leaves=nl,min_child_samples=mcs,reg_alpha=ra),trainx,trainy,valx,valy)\n",
    "            fine_tuning_lgbm.append([nl,mcs,ra,acc])\n",
    "\n",
    "df=pd.DataFrame(fine_tuning_lgbm,columns=[\"num_leaves\",\"min_child_samples\",\"reg_alpha\",\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_leaves           60.000000\n",
       "min_child_samples    50.000000\n",
       "reg_alpha             3.000000\n",
       "accuracy              0.975137\n",
       "Name: 93, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['accuracy'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_prediction(lgb.LGBMClassifier(n_estimators=100,num_leaves=600,min_child_samples=50,reg_alpha=3),\"LGBM\")\n",
    "#0.96970 on kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DART LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_prediction(lgb.LGBMClassifier(boosting_type='dart',n_estimators=150),\"LGBM\")#Score 0.97382 on Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here is the best result we had on kaggle now let's try to fine tune it we saw previously that having a small learning is not useful so we will tune on the other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_leaves=[55,80,100]\n",
    "min_child_samples=[50,65,80]\n",
    "reg_alpha=[i for i in range(5)]\n",
    "fine_tuning_lgbm_dart=[]\n",
    "for nl in num_leaves:\n",
    "    for mcs in min_child_samples:\n",
    "        for ra in reg_alpha:\n",
    "            acc=fine_tune(lgb.LGBMClassifier(boosting_type='dart',n_estimators=100,num_leaves=nl,min_child_samples=mcs,reg_alpha=ra),trainx,trainy,valx,valy)\n",
    "            fine_tuning_lgbm_dart.append([nl,mcs,ra,acc])\n",
    "\n",
    "df_dart=pd.DataFrame(fine_tuning_lgbm_dart,columns=[\"num_leaves\",\"min_child_samples\",\"reg_alpha\",\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_leaves           100.000000\n",
       "min_child_samples     80.000000\n",
       "reg_alpha              2.000000\n",
       "accuracy               0.974146\n",
       "Name: 42, dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dart.loc[df_dart['accuracy'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9731822760405948"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune(lgb.LGBMClassifier(boosting_type='dart',n_estimators=100),trainx,trainy,valx,valy) #acc former dart model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a gain of 0.1% in accuracy compared to the former dart model but in submitting on Kaggle the best result were with the default dart model with a number of estimators of 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_prediction(lgb.LGBMClassifier(boosting_type='dart',n_estimators=100),\"best_LGBM_DART\")#Score 0.97386 on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_prediction(lgb.LGBMClassifier(boosting_type='dart',n_estimators=100,num_leaves=100,min_child_samples=80,reg_alpha=2),\"LGBM_DART_Tuned\")\n",
    "#Score 0.97257"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6c073d106b6caaeb615dd264a7a4f94218eec93e94f5cf912ee643af184d10c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
